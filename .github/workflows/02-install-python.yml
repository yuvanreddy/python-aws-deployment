name: 02 - Install Python

on:
  workflow_dispatch:
    inputs:
      python_version:
        description: 'Python version to install'
        required: false
        default: '3.11'
        type: choice
        options:
          - '3.9'
          - '3.10'
          - '3.11'
          - '3.12'
      install_pip_packages:
        description: 'Additional pip packages to install (comma-separated)'
        required: false
        default: 'boto3,requests,pandas,numpy'
        type: string
      verify_installation:
        description: 'Run verification tests after installation'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  get_infrastructure_info:
    name: Get Infrastructure Information
    runs-on: ubuntu-latest
    outputs:
      instance_ids: ${{ steps.get_outputs.outputs.instance_ids }}
      public_ips: ${{ steps.get_outputs.outputs.public_ips }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
          terraform_wrapper: false

      - name: Reset DynamoDB table for state locking
        run: |
          TABLE_NAME="terraform-state-lock-python-deployment"
          REGION="${{ secrets.AWS_REGION }}"

          # If table exists, delete it to clear any stale Digest mismatches
          if aws dynamodb describe-table --table-name "$TABLE_NAME" --region "$REGION" >/dev/null 2>&1; then
            echo "ðŸ—‘ï¸ Deleting existing DynamoDB table: $TABLE_NAME"
            aws dynamodb delete-table --table-name "$TABLE_NAME" --region "$REGION"
            echo "â³ Waiting for table to be deleted..."
            aws dynamodb wait table-not-exists --table-name "$TABLE_NAME" --region "$REGION"
            echo "âœ… Deleted table: $TABLE_NAME"
          else
            echo "â„¹ï¸ Table not found, nothing to delete: $TABLE_NAME"
          fi

          echo "ðŸ”’ Creating DynamoDB table for state locking: $TABLE_NAME"
          aws dynamodb create-table \
            --table-name "$TABLE_NAME" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST \
            --region "$REGION"

          echo "â³ Waiting for table to be active..."
          aws dynamodb wait table-exists --table-name "$TABLE_NAME" --region "$REGION"
          echo "âœ… DynamoDB table created successfully"

      - name: Initialize Terraform
        working-directory: terraform
        run: |
          BUCKET_NAME="terraform-state-${{ github.repository_owner }}-python-deployment"
          BUCKET_NAME=$(echo "$BUCKET_NAME" | tr '[:upper:]' '[:lower:]' | tr '_' '-')

          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "$BUCKET_NAME"
              key            = "python-deployment/terraform.tfstate"
              region         = "${{ secrets.AWS_REGION }}"
              encrypt        = true
              dynamodb_table = "terraform-state-lock-python-deployment"
            }
          }
          EOF
          
          # Retry terraform init to handle transient S3/DynamoDB eventual consistency
          ATTEMPTS=0
          until terraform init -reconfigure; do
            ATTEMPTS=$((ATTEMPTS+1))
            if [ "$ATTEMPTS" -ge 3 ]; then
              echo "âŒ Terraform init failed after $ATTEMPTS attempts"
              exit 1
            fi
            echo "âš ï¸ terraform init failed (attempt $ATTEMPTS). Retrying in 20s..."
            sleep 20
          done

      - name: Get Terraform outputs
        id: get_outputs
        working-directory: terraform
        run: |
          # Retry terraform output to handle transient state availability
          ATTEMPTS=0
          until INSTANCE_IDS=$(terraform output -json instance_ids 2>/dev/null); do
            ATTEMPTS=$((ATTEMPTS+1))
            if [ "$ATTEMPTS" -ge 3 ]; then
              echo "âŒ Failed to read instance_ids after $ATTEMPTS attempts"
              INSTANCE_IDS="[]"
              break
            fi
            echo "âš ï¸ terraform output instance_ids failed (attempt $ATTEMPTS). Retrying in 10s..."
            sleep 10
          done

          ATTEMPTS=0
          until PUBLIC_IPS=$(terraform output -json public_ips 2>/dev/null); do
            ATTEMPTS=$((ATTEMPTS+1))
            if [ "$ATTEMPTS" -ge 3 ]; then
              echo "âŒ Failed to read public_ips after $ATTEMPTS attempts"
              PUBLIC_IPS="[]"
              break
            fi
            echo "âš ï¸ terraform output public_ips failed (attempt $ATTEMPTS). Retrying in 10s..."
            sleep 10
          done
          
          echo "instance_ids=$INSTANCE_IDS" >> $GITHUB_OUTPUT
          echo "public_ips=$PUBLIC_IPS" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Found instances: $INSTANCE_IDS"

  install_python:
    name: Install Python on EC2 Instances
    needs: get_infrastructure_info
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Ansible
        run: |
          python -m pip install --upgrade pip
          pip install ansible boto3 botocore
          ansible-galaxy collection install amazon.aws
          ansible-galaxy collection install ansible.posix
          echo "âœ… Ansible installed"

      - name: Create Ansible inventory
        run: |
          mkdir -p ansible/inventory
          cat > ansible/inventory/hosts.yml << 'EOF'
          plugin: amazon.aws.aws_ec2
          regions:
            - ${{ secrets.AWS_REGION }}
          filters:
            instance-state-name: running
            tag:ManagedBy: Terraform
            tag:Project: PythonDeployment
          keyed_groups:
            - key: tags
              prefix: tag
          hostnames:
            - instance-id
          compose:
            ansible_host: public_ip_address
          EOF
          
          echo "âœ… Ansible inventory created"

      - name: Wait for instances to be SSH ready
        run: |
          INSTANCE_IDS='${{ needs.get_infrastructure_info.outputs.instance_ids }}'
          echo "â³ Waiting for SSH to be ready on all instances..."
          
          echo "$INSTANCE_IDS" | jq -r '.[]' | while read -r instance_id; do
            PUBLIC_IP=$(aws ec2 describe-instances \
              --instance-ids "$instance_id" \
              --query 'Reservations[0].Instances[0].PublicIpAddress' \
              --output text)
            
            if [ "$PUBLIC_IP" != "None" ] && [ -n "$PUBLIC_IP" ]; then
              echo "Waiting for SSH on $instance_id ($PUBLIC_IP)..."
              timeout 300 bash -c "until nc -zv $PUBLIC_IP 22 2>/dev/null; do sleep 5; done"
              echo "âœ… SSH is ready on $instance_id"
            fi
          done

      - name: Run Ansible playbook
        env:
          ANSIBLE_HOST_KEY_CHECKING: False
          ANSIBLE_PYTHON_INTERPRETER: auto_silent
        run: |
          cd ansible
          echo "ðŸš€ Installing Python on all instances..."
          
          # Create ansible.cfg
          cat > ansible.cfg << EOF
          [defaults]
          host_key_checking = False
          interpreter_python = auto_silent
          remote_user = ubuntu
          private_key_file = ~/.ssh/id_rsa
          timeout = 30
          
          [ssh_connection]
          ssh_args = -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no
          pipelining = True
          EOF
          
          # Run playbook using AWS SSM
          ansible-playbook install_python.yml \
            -i inventory/hosts.yml \
            --connection aws_ssm \
            --extra-vars "ansible_aws_ssm_region=${{ secrets.AWS_REGION }} python_version=${{ github.event.inputs.python_version || '3.11' }} pip_packages=${{ github.event.inputs.install_pip_packages || 'boto3,requests,pandas,numpy' }}" \
            -v
          
          echo "âœ… Python installation completed"

  verify_installation:
    name: Verify Python Installation
    needs: [get_infrastructure_info, install_python]
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.verify_installation != 'false' }}
    
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Verify Python on all instances
        run: |
          INSTANCE_IDS='${{ needs.get_infrastructure_info.outputs.instance_ids }}'
          echo "ðŸ” Verifying Python installation on all instances..."
          
          FAILED_INSTANCES=""
          
          echo "$INSTANCE_IDS" | jq -r '.[]' | while read -r instance_id; do
            echo "----------------------------------------"
            echo "Verifying instance: $instance_id"
            
            # Send command to check Python
            COMMAND_ID=$(aws ssm send-command \
              --instance-ids "$instance_id" \
              --document-name "AWS-RunShellScript" \
              --parameters 'commands=["python3 --version","pip3 --version","pip3 list"]' \
              --output text \
              --query 'Command.CommandId')
            
            # Wait for command to complete
            sleep 5
            
            # Get command result
            STATUS=$(aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "$instance_id" \
              --query 'Status' \
              --output text)
            
            if [ "$STATUS" == "Success" ]; then
              OUTPUT=$(aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$instance_id" \
                --query 'StandardOutputContent' \
                --output text)
              
              echo "âœ… Python verified on $instance_id:"
              echo "$OUTPUT"
            else
              echo "âŒ Failed to verify Python on $instance_id"
              FAILED_INSTANCES="$FAILED_INSTANCES $instance_id"
            fi
          done
          
          if [ -n "$FAILED_INSTANCES" ]; then
            echo "âš ï¸ Failed instances: $FAILED_INSTANCES"
            exit 1
          else
            echo "âœ… Python successfully installed and verified on all instances!"
          fi

      - name: Summary
        run: |
          echo "========================================="
          echo "âœ… PYTHON INSTALLATION COMPLETE"
          echo "========================================="
          echo "Python Version: ${{ github.event.inputs.python_version || '3.11' }}"
          echo "Installed Packages: ${{ github.event.inputs.install_pip_packages || 'boto3,requests,pandas,numpy' }}"
          echo "========================================="
          echo "Next steps:"
          echo "1. Your instances are ready for Python workloads"
          echo "2. To destroy infrastructure, run '03 - Destroy Infrastructure' workflow"
          echo "========================================="